package com.ironcorelabs.large;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.ironcorelabs.tenantsecurity.kms.v1.*;
import com.ironcorelabs.tenantsecurity.kms.v1.exception.*;
import java.io.File;
import java.io.IOException;
import java.io.UncheckedIOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.AbstractMap;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.ExecutionException;
import java.util.stream.Collectors;
import java.util.stream.Stream;

public class LargeDocuments {
  public static void main(String[] args) throws Exception {
    // In order to communicate with the TSP, you need a matching API_KEY. Find the
    // right value from end of the TSP configuration file, and set the API_KEY
    // environment variable to that value.
    String API_KEY = System.getenv("API_KEY");
    if (API_KEY == null) {
      System.out.println("Must set the API_KEY environment variable.");
      System.exit(1);
    }

    // For this example, make sure you use a tenant that has security event logging
    // enabled so you can actually see the events logged to the appropriate SIEM.
    String TENANT_ID = System.getenv("TENANT_ID");
    if (TENANT_ID == null) {
      TENANT_ID = "tenant-gcp";
    }
    System.out.println("Using tenant " + TENANT_ID);

    // Initialize the client with a Tenant Security Proxy domain and API key.
    // Typically this would be done once when the application or service initializes
    TenantSecurityClient client =
        TenantSecurityClient.create("http://localhost:32804", API_KEY).get();

    // Create metadata used to associate this document to a tenant, name the
    // document, and identify the service or user making the call
    DocumentMetadata metadata = new DocumentMetadata(TENANT_ID, "serviceOrUserId", "PII");

    // Example 1: encrypting a large document, using the filesystem for persistence
    //
    // This whole file is an example of how you can avoid calls to the KMS/TSP when
    // you have a tightly defined "document", even if that document is actually made
    // up of many entities in a database. This shouldn't be done with disparate
    // pieces of data that will commonly be decrypted/encrypted separately from each
    // other. At that point using `[encrypt|decrypt]DocumentBatch()` is the better
    // option, allowing you to make a single call to the TSP but still have
    // different keys for each data piece.

    String filename = "large-document.json";
    String subfolder = "sub-docs";

    // create a place to put files generated by this run
    Path tmpFileDir = Files.createTempDirectory("saas-shield");
    System.out.println("Writing encrypted files to: " + tmpFileDir);

    ObjectMapper objectMapper = new ObjectMapper();
    BigDoc sourceObj = objectMapper.readValue(new File("./resources/" + filename), BigDoc.class);

    // Reduce the document to a map of all the sub documents to be encrypted with
    // the same key
    Map<String, byte[]> docToEncrypt =
        Stream.of(sourceObj.subDocs)
            .map(
                subDoc -> {
                  try {
                    byte[] value = objectMapper.writeValueAsString(subDoc).getBytes();
                    return new AbstractMap.SimpleEntry<>(subDoc.subDocId, value);
                  } catch (com.fasterxml.jackson.core.JsonProcessingException e) {
                    throw new UncheckedIOException(e);
                  }
                })
            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));

    try {
      // Request a key from the KMS and use it to encrypt all the sub documents
      EncryptedDocument encryptedDocument = client.encrypt(docToEncrypt, metadata).get();

      // write the encrypted key to the filesystem
      String encryptedDocumentEncryptionKey = encryptedDocument.getEdek();
      Path edekPath = Paths.get(tmpFileDir.toString(), filename + ".edek");
      Files.write(edekPath, encryptedDocumentEncryptionKey.getBytes());

      // write the encrypted docs to the filesystem
      encryptedDocument.getEncryptedFields().entrySet().stream()
          .forEach(
              entry -> {
                String subDocId = entry.getKey();
                Path subDocPath = Paths.get(tmpFileDir.toString(), subDocId + ".enc");
                byte[] subDocEncryptedBytes = entry.getValue();
                try {
                  Files.write(subDocPath, subDocEncryptedBytes);
                } catch (IOException e) {
                  throw new UncheckedIOException(e);
                }
              });
    } catch (ExecutionException e) {
      if (e.getCause() instanceof TenantSecurityException) {
        TenantSecurityException error = (TenantSecurityException) e.getCause();
        TenantSecurityErrorCodes errorCode = error.getErrorCode();
        System.out.println("\nError Message: " + error.getMessage());
        System.out.println("\nError Code: " + errorCode.getCode());
        System.out.println("\nError Code Info: " + errorCode.getMessage() + "\n");
      }
      throw e;
    }

    //
    // Example 2: update two subdocuments in our persistence layer
    //
    String subDocId1 = "4c3173c3-8e09-49eb-a4ee-428e2dbf5296";
    String subDocId2 = "4e57e8bd-d88a-4083-9fac-05a635110e2a";

    // Read the two files out first
    byte[] encryptedFile1 =
        Files.readAllBytes(Paths.get(tmpFileDir.toString(), subDocId1 + ".enc"));
    byte[] encryptedFile2 =
        Files.readAllBytes(Paths.get(tmpFileDir.toString(), subDocId2 + ".enc"));

    // In a DB situation this edek could be stored with the large doc (if sub docs
    // are only decrypted in that context) or it could be stored alongside each
    // sub-document. In the latter case you make it harder to accidentally
    // cryptoshred data by de-syncing edeks at the cost of row size
    String edek =
        new String(Files.readAllBytes(Paths.get(tmpFileDir.toString(), filename + ".edek")));

    // each of the documents could be individually decrypted with their own calls,
    // but by combining them into one structure we ensure we only make one call to
    // the KMS to unwrap the key
    Map<String, byte[]> encryptedPartDocMap = new HashMap<>();
    encryptedPartDocMap.put(subDocId1, encryptedFile1);
    encryptedPartDocMap.put(subDocId2, encryptedFile2);
    EncryptedDocument encryptedPartialBigDoc = new EncryptedDocument(encryptedPartDocMap, edek);

    // Decrypt the two subdocuments
    PlaintextDocument decryptedPartialBigDoc =
        client.decrypt(encryptedPartialBigDoc, metadata).get();

    // Turn the decrypted bytes back into objects
    SubDoc reSubDoc1 =
        objectMapper.readValue(
            new String(decryptedPartialBigDoc.getDecryptedFields().get(subDocId1)), SubDoc.class);
    SubDoc reSubDoc2 =
        objectMapper.readValue(
            new String(decryptedPartialBigDoc.getDecryptedFields().get(subDocId2)), SubDoc.class);
    // just so we can write it out nicely
    BigDoc rePartialBigDoc = new BigDoc("x", "x", "x", new SubDoc[] {reSubDoc1, reSubDoc2});

    // Write out the rehydrated docs as proof that things round tripped fine
    Files.write(
        Paths.get(tmpFileDir.toString(), "partial-large-document.json"),
        objectMapper.writeValueAsString(rePartialBigDoc).getBytes());

    System.exit(0);
  }
  ;
}
